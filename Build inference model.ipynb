{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T14:35:31.860042Z",
     "start_time": "2020-07-03T14:35:27.704229Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from elmo import Model\n",
    "from collections import defaultdict\n",
    "from elmo_utils import *\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 忽略警告\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "try:\n",
    "    from tensorflow.python.util import module_wrapper as deprecation\n",
    "except ImportError:\n",
    "    from tensorflow.python.util import deprecation_wrapper as deprecation\n",
    "deprecation._PER_MODULE_WARNING_LIMIT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T14:35:32.019114Z",
     "start_time": "2020-07-03T14:35:32.005116Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = \"output/elmo_origin_loss_fix_at_best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T14:35:47.118277Z",
     "start_time": "2020-07-03T14:35:33.007490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading config from output/elmo_origin_loss_fix_at_best\\config\n",
      "# Start to load pretrained embedding...\n",
      "# vocab size:  50000\n",
      "# pretrained embedding size 44512 300\n",
      "构建elmo静态图...\n"
     ]
    }
   ],
   "source": [
    "inference_graph = tf.Graph()\n",
    "\n",
    "with inference_graph.as_default():\n",
    "    inference_config = load_config(checkpoint_dir,\n",
    "                                {\"mode\":'inference', 'checkpoint_dir':checkpoint_dir+\"/best_eval\"})\n",
    "    inference_model = Model(inference_config)\n",
    "    inference_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T14:35:57.936893Z",
     "start_time": "2020-07-03T14:35:57.930893Z"
    }
   },
   "outputs": [],
   "source": [
    "export_path = os.path.join(\n",
    "        tf.compat.as_bytes('serving/'),\n",
    "        tf.compat.as_bytes('v1/001')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T14:37:41.889770Z",
     "start_time": "2020-07-03T14:37:17.879470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!! Restored model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=inference_graph, config=get_config_proto(log_device_placement=False)) as inference_sess:\n",
    "    inference_model.init_model(inference_sess)\n",
    "    inference_model.restore_model(inference_sess)\n",
    "    \n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "    \n",
    "    inputs_text_ids = inference_model.inputs\n",
    "    inputs_text_lens = inference_model.seq_len\n",
    "    \n",
    "    predicts = inference_model.all_predicts\n",
    "    logits = inference_model.all_logits\n",
    "    \n",
    "    inputs = {'text_ids': tf.saved_model.utils.build_tensor_info(inputs_text_ids),\n",
    "                   'text_lens': tf.saved_model.utils.build_tensor_info(inputs_text_lens)}\n",
    "    outputs = {'predicts': tf.saved_model.utils.build_tensor_info(predicts),\n",
    "                     'logits': tf.saved_model.utils.build_tensor_info(logits)}\n",
    "    \n",
    "    signature = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\n",
    "    \n",
    "    builder.add_meta_graph_and_variables(inference_sess, \n",
    "                                         [tf.saved_model.tag_constants.SERVING], \n",
    "                                         {'predict_labels':signature})\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T15:03:24.376712Z",
     "start_time": "2020-07-03T15:03:23.905737Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T15:04:38.017687Z",
     "start_time": "2020-07-03T15:04:34.632367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# vocab size:  50000\n",
      "# vocab size:  20\n",
      "# Start to preprocessing data...\n",
      "# load data from data/validation.json ...\n",
      "# Got 15000 data items with 117 batches\n"
     ]
    }
   ],
   "source": [
    "from dataset import DataSet\n",
    "\n",
    "\n",
    "eval_dataset = DataSet([\"data/validation.json\"],\n",
    "                           \"data/vocab.txt\",\n",
    "                           \"data/labels.txt\",\n",
    "                           128,\n",
    "                           reverse=False,\n",
    "                           split_word=True,\n",
    "                           max_len=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T15:07:08.451815Z",
     "start_time": "2020-07-03T15:07:07.969440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1    48     7 ...   908   586     2]\n",
      " [    1  1490   172 ...    31 16300     2]\n",
      " [    1    21   350 ...   325  3904     2]\n",
      " ...\n",
      " [    1   269   108 ...     2     2     2]\n",
      " [    1  6520    63 ...     2     2     2]\n",
      " [    1  3847 26296 ...     2     2     2]]\n",
      "[1202 1202 1202 1202 1202 1202 1189 1166 1154 1126 1100 1096 1086 1054\n",
      " 1038 1026 1023 1016 1010 1008  979  978  972  966  958  946  926  921\n",
      "  910  910  888  877  876  870  856  850  839  837  835  833  827  822\n",
      "  821  820  817  815  811  810  807  806  804  789  787  781  778  773\n",
      "  756  755  754  753  741  738  727  726  723  712  711  711  708  707\n",
      "  707  706  704  700  700  694  693  689  687  683  680  677  672  672\n",
      "  671  669  668  668  666  657  654  651  650  650  647  647  646  645\n",
      "  644  642  641  640  637  637  636  630  630  626  623  622  622  622\n",
      "  622  618  613  611  611  609  608  606  606  601  598  596  596  595\n",
      "  593  592]\n",
      "[[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]]\n",
      "[14899, 14151, 13654, 14269, 3330, 12657, 14630, 14250, 7107, 12495, 1086, 14928, 6367, 4973, 11521, 3516, 13234, 5550, 8224, 8059, 1296, 12248, 4350, 12204, 13949, 1874, 6578, 12334, 3869, 14712, 14271, 1404, 1508, 3255, 1034, 10689, 7948, 2598, 13604, 4072, 7960, 7632, 2831, 7572, 4435, 2311, 4409, 14231, 143, 2293, 317, 6169, 6483, 2539, 10956, 9617, 3911, 5840, 7792, 1043, 1848, 8282, 8318, 13504, 9169, 10742, 6036, 6436, 2983, 14729, 5716, 8383, 7866, 5253, 3774, 9577, 10404, 9871, 10097, 13614, 8517, 10496, 3960, 12783, 13841, 12060, 4051, 8742, 3468, 245, 13877, 11132, 7085, 2398, 6909, 6841, 13158, 3512, 5719, 5523, 2922, 10842, 4724, 14610, 12929, 8402, 4404, 14546, 9773, 11265, 11944, 14377, 10068, 10371, 5347, 11531, 10361, 8399, 9965, 11159, 8240, 1028, 6693, 10618, 4128, 11463, 12375, 8278]\n"
     ]
    }
   ],
   "source": [
    "for i in eval_dataset.get_next():\n",
    "    print(i[0])\n",
    "    print(i[1])\n",
    "    print(i[2])\n",
    "    print(i[3])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
