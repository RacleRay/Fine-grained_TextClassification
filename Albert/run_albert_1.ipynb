{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_albert_tiny","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN6Pi3rsMmOu19F3toZ4o/O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1372e47138ec4b9c8ca2abbb478062ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_97b850955256425d917c05765eb5f789","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0ca5cd3314ec416b8a837daa5ea4963b","IPY_MODEL_1a1beff36bd249ddabf6f730fdd35248"]}},"97b850955256425d917c05765eb5f789":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ca5cd3314ec416b8a837daa5ea4963b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_459aff9304fd42188cad8e19b3476bcd","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1875,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1875,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2603d0fda442471c8206184112c81df0"}},"1a1beff36bd249ddabf6f730fdd35248":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6abc9dfb3dc4435c96fc337e3ba8c900","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1875/1875 [1:11:58&lt;00:00,  2.30s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae7f7e16ba894f0f9814230be903ce7a"}},"459aff9304fd42188cad8e19b3476bcd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2603d0fda442471c8206184112c81df0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6abc9dfb3dc4435c96fc337e3ba8c900":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ae7f7e16ba894f0f9814230be903ce7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"HxZRZ8OhhMi-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1590808251654,"user_tz":-480,"elapsed":1174,"user":{"displayName":"Racle He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNRi7DUXsEvpMRqVqHTUF_Oen4KW7kU7MKQekk=s64","userId":"10673173760458122172"}},"outputId":"78cced6a-b8bd-42ef-90b5-64b1a2dc448b"},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M8HjPPzAh3Kg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":179},"executionInfo":{"status":"ok","timestamp":1590808258573,"user_tz":-480,"elapsed":5021,"user":{"displayName":"Racle He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNRi7DUXsEvpMRqVqHTUF_Oen4KW7kU7MKQekk=s64","userId":"10673173760458122172"}},"outputId":"aa0b18c4-c7d6-49f1-91d4-e9651bde1ed0"},"source":["% cd /content/gdrive/My\\ Drive/Colab\\ Notebooks/nlp_task/bert_cla\n","! pwd\n","! ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/nlp_task/bert_cla\n","/content/gdrive/My Drive/Colab Notebooks/nlp_task/bert_cla\n","albert_large\t  __init__.py\t\t  run_multi_label_linear.py\n","albert_tiny\t  main.py\t\t  runs\n","apex\t\t  models\t\t  train.tsv\n","base_runner.py\t  outputs\t\t  val.tsv\n","base_utils.py\t  __pycache__\t\t  wandb\n","cache_dir\t  run.ipynb\t\t  xbert_cnn_runner.py\n","global_config.py  run_multi_class_cnn.py  xbert_multi_label_linear_runner.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7N7a-8ApiKoD","colab_type":"code","colab":{}},"source":["!pip install wandb tensorboardX transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1MWaIokuijcW","colab_type":"code","colab":{}},"source":["# !git clone https://github.com/NVIDIA/apex\n","%cd apex\n","!python setup.py install --cpp_ext --cuda_ext\n","%cd .."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1R65oUsolYd","colab_type":"code","colab":{}},"source":["!/opt/bin/nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nB212nZZjQ3o","colab_type":"code","colab":{}},"source":["!python main.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NepkmOW4mk7c","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import sklearn\n","from sklearn.preprocessing import OneHotEncoder\n","from xbert_multi_label_linear_runner import MultiBinaryClaRunner\n","\n","\n","def process_tsv(file):\n","    \"根据数据的储存方式修改\"\n","    data = pd.read_table(file, names=['label', 'text'], encoding='utf-8')\n","    label = data.label.apply(lambda x: x.split('@'))\n","    label = np.array(label.to_list())\n","    enc = OneHotEncoder()\n","    # '0_-1', '0_-2', '0_0', '0_1' => 1000, 0100, 0010, 0001\n","    label_ont_hot = enc.fit_transform(label)\n","    for i, row_label in enumerate(label_ont_hot.toarray()):\n","        data.iloc[i]['label'] = row_label\n","    return data\n","\n","\n","def main():\n","    \"查看训练效果\"\n","    eval_df = process_tsv('val.tsv')\n","    model = MultiBinaryClaRunner('albert',\n","                                 './outputs/checkpoint-12000',\n","                                 num_labels=80,\n","                                 use_cuda=False,\n","                                 args={\n","                                     \"reprocess_input_data\": False,\n","                                     \"overwrite_output_dir\": False,\n","                                     \"num_train_epochs\": 5,\n","                                     \"use_cached_eval_features\": True,\n","                                 })\n","    \n","    result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n","    print(result)\n","    print(model_outputs)\n","    return model_outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUG2CxsBPLsc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1372e47138ec4b9c8ca2abbb478062ba","97b850955256425d917c05765eb5f789","0ca5cd3314ec416b8a837daa5ea4963b","1a1beff36bd249ddabf6f730fdd35248","459aff9304fd42188cad8e19b3476bcd","2603d0fda442471c8206184112c81df0","6abc9dfb3dc4435c96fc337e3ba8c900","ae7f7e16ba894f0f9814230be903ce7a"]},"executionInfo":{"status":"ok","timestamp":1590811084727,"user_tz":-480,"elapsed":636083,"user":{"displayName":"Racle He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNRi7DUXsEvpMRqVqHTUF_Oen4KW7kU7MKQekk=s64","userId":"10673173760458122172"}},"outputId":"f49e9975-d2e2-4a7e-de8d-3481271ce578"},"source":["model_outputs = main()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:transformers.configuration_utils:loading configuration file ./outputs/checkpoint-12000/config.json\n","INFO:transformers.configuration_utils:Model config AlbertConfig {\n","  \"architectures\": [\n","    \"AlbertForMultiBinaryLabelSeqClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 312,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\",\n","    \"20\": \"LABEL_20\",\n","    \"21\": \"LABEL_21\",\n","    \"22\": \"LABEL_22\",\n","    \"23\": \"LABEL_23\",\n","    \"24\": \"LABEL_24\",\n","    \"25\": \"LABEL_25\",\n","    \"26\": \"LABEL_26\",\n","    \"27\": \"LABEL_27\",\n","    \"28\": \"LABEL_28\",\n","    \"29\": \"LABEL_29\",\n","    \"30\": \"LABEL_30\",\n","    \"31\": \"LABEL_31\",\n","    \"32\": \"LABEL_32\",\n","    \"33\": \"LABEL_33\",\n","    \"34\": \"LABEL_34\",\n","    \"35\": \"LABEL_35\",\n","    \"36\": \"LABEL_36\",\n","    \"37\": \"LABEL_37\",\n","    \"38\": \"LABEL_38\",\n","    \"39\": \"LABEL_39\",\n","    \"40\": \"LABEL_40\",\n","    \"41\": \"LABEL_41\",\n","    \"42\": \"LABEL_42\",\n","    \"43\": \"LABEL_43\",\n","    \"44\": \"LABEL_44\",\n","    \"45\": \"LABEL_45\",\n","    \"46\": \"LABEL_46\",\n","    \"47\": \"LABEL_47\",\n","    \"48\": \"LABEL_48\",\n","    \"49\": \"LABEL_49\",\n","    \"50\": \"LABEL_50\",\n","    \"51\": \"LABEL_51\",\n","    \"52\": \"LABEL_52\",\n","    \"53\": \"LABEL_53\",\n","    \"54\": \"LABEL_54\",\n","    \"55\": \"LABEL_55\",\n","    \"56\": \"LABEL_56\",\n","    \"57\": \"LABEL_57\",\n","    \"58\": \"LABEL_58\",\n","    \"59\": \"LABEL_59\",\n","    \"60\": \"LABEL_60\",\n","    \"61\": \"LABEL_61\",\n","    \"62\": \"LABEL_62\",\n","    \"63\": \"LABEL_63\",\n","    \"64\": \"LABEL_64\",\n","    \"65\": \"LABEL_65\",\n","    \"66\": \"LABEL_66\",\n","    \"67\": \"LABEL_67\",\n","    \"68\": \"LABEL_68\",\n","    \"69\": \"LABEL_69\",\n","    \"70\": \"LABEL_70\",\n","    \"71\": \"LABEL_71\",\n","    \"72\": \"LABEL_72\",\n","    \"73\": \"LABEL_73\",\n","    \"74\": \"LABEL_74\",\n","    \"75\": \"LABEL_75\",\n","    \"76\": \"LABEL_76\",\n","    \"77\": \"LABEL_77\",\n","    \"78\": \"LABEL_78\",\n","    \"79\": \"LABEL_79\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 1248,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_20\": 20,\n","    \"LABEL_21\": 21,\n","    \"LABEL_22\": 22,\n","    \"LABEL_23\": 23,\n","    \"LABEL_24\": 24,\n","    \"LABEL_25\": 25,\n","    \"LABEL_26\": 26,\n","    \"LABEL_27\": 27,\n","    \"LABEL_28\": 28,\n","    \"LABEL_29\": 29,\n","    \"LABEL_3\": 3,\n","    \"LABEL_30\": 30,\n","    \"LABEL_31\": 31,\n","    \"LABEL_32\": 32,\n","    \"LABEL_33\": 33,\n","    \"LABEL_34\": 34,\n","    \"LABEL_35\": 35,\n","    \"LABEL_36\": 36,\n","    \"LABEL_37\": 37,\n","    \"LABEL_38\": 38,\n","    \"LABEL_39\": 39,\n","    \"LABEL_4\": 4,\n","    \"LABEL_40\": 40,\n","    \"LABEL_41\": 41,\n","    \"LABEL_42\": 42,\n","    \"LABEL_43\": 43,\n","    \"LABEL_44\": 44,\n","    \"LABEL_45\": 45,\n","    \"LABEL_46\": 46,\n","    \"LABEL_47\": 47,\n","    \"LABEL_48\": 48,\n","    \"LABEL_49\": 49,\n","    \"LABEL_5\": 5,\n","    \"LABEL_50\": 50,\n","    \"LABEL_51\": 51,\n","    \"LABEL_52\": 52,\n","    \"LABEL_53\": 53,\n","    \"LABEL_54\": 54,\n","    \"LABEL_55\": 55,\n","    \"LABEL_56\": 56,\n","    \"LABEL_57\": 57,\n","    \"LABEL_58\": 58,\n","    \"LABEL_59\": 59,\n","    \"LABEL_6\": 6,\n","    \"LABEL_60\": 60,\n","    \"LABEL_61\": 61,\n","    \"LABEL_62\": 62,\n","    \"LABEL_63\": 63,\n","    \"LABEL_64\": 64,\n","    \"LABEL_65\": 65,\n","    \"LABEL_66\": 66,\n","    \"LABEL_67\": 67,\n","    \"LABEL_68\": 68,\n","    \"LABEL_69\": 69,\n","    \"LABEL_7\": 7,\n","    \"LABEL_70\": 70,\n","    \"LABEL_71\": 71,\n","    \"LABEL_72\": 72,\n","    \"LABEL_73\": 73,\n","    \"LABEL_74\": 74,\n","    \"LABEL_75\": 75,\n","    \"LABEL_76\": 76,\n","    \"LABEL_77\": 77,\n","    \"LABEL_78\": 78,\n","    \"LABEL_79\": 79,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"ln_type\": \"postln\",\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 4,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"share_type\": \"all\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 21128\n","}\n","\n","INFO:transformers.modeling_utils:loading weights file ./outputs/checkpoint-12000/pytorch_model.bin\n","INFO:transformers.tokenization_utils:Model name './outputs/checkpoint-12000' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming './outputs/checkpoint-12000' is a path, a model identifier, or url to a directory containing tokenizer files.\n","INFO:transformers.tokenization_utils:Didn't find file ./outputs/checkpoint-12000/added_tokens.json. We won't load it.\n","INFO:transformers.tokenization_utils:loading file ./outputs/checkpoint-12000/vocab.txt\n","INFO:transformers.tokenization_utils:loading file None\n","INFO:transformers.tokenization_utils:loading file ./outputs/checkpoint-12000/special_tokens_map.json\n","INFO:transformers.tokenization_utils:loading file ./outputs/checkpoint-12000/tokenizer_config.json\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1372e47138ec4b9c8ca2abbb478062ba","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1875.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","{'LRAP': 0.8503416726137365, 'eval_loss': 0.2725202091852824}\n","[[0.00418422 0.9829518  0.00285136 ... 0.7647685  0.01880348 0.15971665]\n"," [0.05347089 0.3439139  0.06759455 ... 0.47151136 0.03505317 0.62766325]\n"," [0.0066029  0.97901857 0.00484641 ... 0.74131244 0.04904596 0.09119504]\n"," ...\n"," [0.00493792 0.9439298  0.00663487 ... 0.34487233 0.01076601 0.67223877]\n"," [0.00395735 0.9822786  0.00330733 ... 0.6269512  0.01819935 0.32523066]\n"," [0.03622032 0.12109882 0.04457749 ... 0.4758353  0.01685664 0.529969  ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bxPjPSG3wm6R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1590811593979,"user_tz":-480,"elapsed":931,"user":{"displayName":"Racle He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNRi7DUXsEvpMRqVqHTUF_Oen4KW7kU7MKQekk=s64","userId":"10673173760458122172"}},"outputId":"16bbd9d9-0e4d-4649-c823-ea58512dc2c5"},"source":["type(model_outputs)\n","model_outputs.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15000, 80)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"McBkxXx-x9J8","colab_type":"code","colab":{}},"source":["m = np.hsplit(model_outputs, 20)  # 每种label的预测\n","print(m[0].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xp3JFDGw3UJg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1590813583138,"user_tz":-480,"elapsed":1813,"user":{"displayName":"Racle He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNRi7DUXsEvpMRqVqHTUF_Oen4KW7kU7MKQekk=s64","userId":"10673173760458122172"}},"outputId":"cde9b512-6ec1-40a0-d87c-8dabdae31ae6"},"source":["y_pre = []\n","for lab in m:\n","    lab_pre = []\n","    for item in lab:\n","        i = np.argmax(item)\n","        new = np.zeros((4))\n","        new[i] = 1\n","        lab_pre.append(new)\n","    y_pre.append(lab_pre)\n","\n","print(len(y_pre))\n","print(len(y_pre[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UCqye9Nkzjta","colab_type":"code","colab":{}},"source":["eval_df = process_tsv('val.tsv')\n","y = eval_df.label.to_numpy()\n","y_split = [np.split(ar, 20) for ar in y]\n","y_zip = list(zip(*y_split))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J59J-MRTz8-c","colab_type":"code","colab":{}},"source":["print(y_split[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6UQX9wf1JIg","colab_type":"code","colab":{}},"source":["def cal_f1(label_num,predicted,truth):\n","    results = []\n","    for i in range(label_num):\n","        results.append({\"TP\": 0, \"FP\": 0, \"FN\": 0, \"TN\": 0})\n","    \n","    for i, p in enumerate(predicted):\n","        t = truth[i]\n","        for j in range(label_num):\n","            if p[j] == 1:\n","                if t[j] == 1:\n","                    results[j]['TP'] += 1\n","                else:\n","                    results[j]['FP'] += 1\n","            else:\n","                if t[j] == 1:\n","                    results[j]['FN'] += 1\n","                else:\n","                    results[j]['TN'] += 1\n","    \n","    precision = [0.0] * label_num\n","    recall = [0.0] * label_num\n","    f1 = [0.0] * label_num\n","    for i in range(label_num):\n","        if results[i]['TP'] == 0:\n","            if results[i]['FP']==0 and results[i]['FN']==0:\n","                precision[i] = 1.0\n","                recall[i] = 1.0\n","                f1[i] = 1.0\n","            else:\n","                precision[i] = 0.0\n","                recall[i] = 0.0\n","                f1[i] = 0.0\n","        else:\n","            precision[i] = results[i]['TP'] / (results[i]['TP'] + results[i]['FP'])\n","            recall[i] = results[i]['TP'] / (results[i]['TP'] + results[i]['FN'])\n","            f1[i] =  2 * precision[i] * recall[i] / (precision[i] + recall[i])\n","    \n","    # for i in range(label_num):\n","    #     print(i,results[i], precision[i], recall[i], f1[i])\n","    return sum(f1)/label_num, sum(precision)/label_num, sum(recall)/label_num"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wjti0a3D24is","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1590813240064,"user_tz":-480,"elapsed":897,"user":{"displayName":"Racle He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNRi7DUXsEvpMRqVqHTUF_Oen4KW7kU7MKQekk=s64","userId":"10673173760458122172"}},"outputId":"8d3c4e6e-7ac1-4240-9e0e-6330370d5d33"},"source":[" m[i]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.01855174, 0.7647685 , 0.01880348, 0.15971665],\n","       [0.01238796, 0.47151136, 0.03505317, 0.62766325],\n","       [0.1077148 , 0.74131244, 0.04904596, 0.09119504],\n","       ...,\n","       [0.00390053, 0.34487233, 0.01076601, 0.67223877],\n","       [0.01361998, 0.6269512 , 0.01819935, 0.32523066],\n","       [0.00492287, 0.4758353 , 0.01685664, 0.529969  ]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"XYZhMTyi1OqO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"status":"ok","timestamp":1590813623804,"user_tz":-480,"elapsed":2020,"user":{"displayName":"Racle He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNRi7DUXsEvpMRqVqHTUF_Oen4KW7kU7MKQekk=s64","userId":"10673173760458122172"}},"outputId":"e5c9d807-5073-4181-c98c-caa20a12b384"},"source":["results = {}\n","total_f1 = 0\n","for i in range(20):\n","    # print(\"# Get f1 score for\",label_name)\n","    f1,precision,recall = cal_f1(4, y_pre[i], y_zip[i])\n","    results[i] = f1\n","    total_f1 += f1\n","    print(\"# {0} - {1}\".format(i,f1))\n","\n","final_f1 = total_f1 / len(results)\n","    \n","print(final_f1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# 0 - 0.4350798956434013\n","# 1 - 0.25423651742976927\n","# 2 - 0.374390923252088\n","# 3 - 0.2343910472075645\n","# 4 - 0.565270394738733\n","# 5 - 0.25308507083415144\n","# 6 - 0.22945955300812967\n","# 7 - 0.359041490735619\n","# 8 - 0.319463242820002\n","# 9 - 0.4501493568128927\n","# 10 - 0.4091086744762951\n","# 11 - 0.3708626074415709\n","# 12 - 0.35268555078063407\n","# 13 - 0.4253311095275243\n","# 14 - 0.3059930302839872\n","# 15 - 0.38861011858904965\n","# 16 - 0.21045234845445976\n","# 17 - 0.3012516641577144\n","# 18 - 0.48432925660342474\n","# 19 - 0.293108032437173\n","0.35081499426170915\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F0i2rkLCPPh-","colab_type":"code","colab":{}},"source":["# print(model_outputs.shape)\n","# m = np.hsplit(model_outputs, 20)\n","# print(m[0].shape)\n","\n","# label_map = {0:  '0_-1', 1:'0_-2', 2:'0_0', 3:'0_1' }\n","# label_pred = []\n","# for lab_item in m:\n","#     # print(lab_item.shape)\n","#     # print(lab_item)\n","    \n","#     pred = np.argmax(lab_item, axis=1)\n","#     # print(pred)\n","#     # print(type(pred))\n","\n","#     l = []\n","#     for i in pred:\n","#         l.append(label_map[i])\n","#     label_pred.append(l)\n","\n","# print(label_pred[:2])\n","# preds = list(zip(*label_pred))"],"execution_count":null,"outputs":[]}]}